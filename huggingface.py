# -*- coding: utf-8 -*-
"""HuggingFace.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CpcoIzjaXs0mCueYhW4CMQ2xRh-Sc7Us
"""

import pandas as pd

df=messages=pd.read_csv('/content/SMSSpamCollection.txt',sep='\t',names=['label','message'])

df.head(10)

df.columns

df.shape

df["label"].value_counts()

df.isnull().sum()

df.duplicated().sum()

df.drop_duplicates(inplace=True)

df.duplicated().sum()

df.describe()

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(6, 4))
sns.countplot(x='label', data=df, hue='label', palette='Set2', legend=False)
plt.title('Spam vs Ham Message Distribution')
plt.xlabel('Message Type')
plt.ylabel('Count')
plt.tight_layout()
plt.savefig("spam_vs_ham_distribution.png")  # or use plt.show() in notebooks

df['labels']=df['label'].apply(lambda x: 1 if x=='spam' else 0)

df.head(10)

X=list(df['message'])

y=list(df['labels'])

"""Train and Test Split"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)

"""Using the the bert transformers"""

from transformers import DistilBertTokenizerFast
tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')

"""Encoding"""

train_encodings = tokenizer(list(X_train), truncation=True, padding=True)
test_encodings = tokenizer((X_test), truncation=True, padding=True)

import torch
train_dataset = torch.utils.data.TensorDataset(torch.tensor(train_encodings['input_ids']),
                                               torch.tensor(train_encodings['attention_mask']),
                                               torch.tensor(y_train))

class SentientDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = SentientDataset(train_encodings, list(y_train))
test_dataset = SentientDataset(test_encodings, list(y_test))

"""Pretraind and Fine tuning"""

from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments
from datasets import Dataset

model=DistilBertForSequenceClassification.from_pretrained("distilbert-base-uncased")

import os
os.environ["WANDB_DISABLED"] = "true"

training_args=TrainingArguments(output_dir='./results',
                                num_train_epochs=2,
                                learning_rate=2e-5,
                                per_device_train_batch_size=8,
                                per_device_eval_batch_size=8,
                                weight_decay=0.01,
                                logging_dir='./logs',
                                logging_steps=10,)

trainer=Trainer(model=model,args=training_args,train_dataset=train_dataset,eval_dataset=test_dataset)

trainer.train()

trainer.evaluate(test_dataset)

"""Prediction"""

trainer.predict(test_dataset)

trainer.predict(test_dataset)[1].shape

output=trainer.predict(test_dataset)[1]

output

from sklearn.metrics import confusion_matrix,classification_report

cm=confusion_matrix(y_test,output)
cm

cr=classification_report(y_test,output)
print(cr)

"""Model Saved"""

model.save_pretrained("saved_distilbert_model")
tokenizer.save_pretrained("saved_distilbert_model")

"""App Running"""

pip install streamlit

"""Streamlit deployment"""

MODEL_NAME='distilbert-base-uncased'
tokenizer=DistilBertTokenizer.from_pretrained(MODEL_NAME)
model=DistilBertForSequenceClassification.from_pretrained(MODEL_NAME,num_labels=2)

"""converting the saved_model to ZIP for future"""

!zip -r saved_distilbert_model.zip saved_distilbert_model/

model.save_pretrained("saved_distilbert_model")
tokenizer.save_pretrained("saved_distilbert_model")

"""Streamlit"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import torch
# from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification
# 
# st.set_page_config(page_title="Spam Detector with DistilBERT", layout="centered")
# st.title("SMS Spam Detection using Hugging Face DistilBERT")
# st.markdown("Enter an SMS message to classify it as **Spam** or **Ham (Not Spam)**.")
# 
# # Load your saved model
# MODEL_PATH = "saved_distilbert_model"
# tokenizer = DistilBertTokenizerFast.from_pretrained(MODEL_PATH)
# model = DistilBertForSequenceClassification.from_pretrained(MODEL_PATH)
# 
# # Input box
# text = st.text_area(" Enter a message:", height=100)
# 
# # Predict
# if st.button(" Classify"):
#     if not text.strip():
#         st.warning("Please enter a valid message.")
#     else:
#         inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)
#         with torch.no_grad():
#             outputs = model(**inputs)
#             logits = outputs.logits
#             prediction = torch.argmax(logits, dim=1).item()
#         if prediction == 1:
#             st.error("This message is classified as **Spam**.")
#         else:
#             st.success(" This message is classified as **Ham (Not Spam)**.")
#

!streamlit run app.py

!ps -ef | grep streamlit

!pkill -f streamlit
!pkill -f ngrok

!ps -ef | grep -E "streamlit|ngrok"

!pip install pyngrok

!rm -f /root/.ngrok2/ngrok.yml /root/.config/ngrok/ngrok.yml

!mkdir -p /root/.config/ngrok && echo "authtoken: 2ze2GNzXW2d1ZrwcUv7k4UAmEvt_6BS6v3Mh5ncGGJ2rNT56a" > /root/.config/ngrok/ngrok.yml

!cat /root/.config/ngrok/ngrok.yml

from pyngrok import ngrok

# Create tunnel to Streamlit port 8501
public_url = ngrok.connect(port=8501)
print(f"🌐 Your Streamlit app is live at: {public_url}")